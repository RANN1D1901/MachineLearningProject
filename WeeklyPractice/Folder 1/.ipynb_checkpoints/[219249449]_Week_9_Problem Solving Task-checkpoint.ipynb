{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking the DatasetL fetch_lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariel Sharon\n",
      "Colin Powell\n",
      "Donald Rumsfeld\n",
      "George W Bush\n",
      "Gerhard Schroeder\n",
      "Hugo Chavez\n",
      "Tony Blair\n"
     ]
    }
   ],
   "source": [
    "# Picking the DatasetL fetch_lfw_people\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "dataset = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "for name in dataset.target_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded: True\n",
      "Target Loaded: True\n",
      "Samples: 1288\n",
      "Features: 1850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_shape = dataset['data'].shape\n",
    "print(\"Data Loaded: {2}\\nTarget Loaded: {3}\\nSamples: {0}\\nFeatures: {1}\\n\"\n",
    "      .format(data_shape[0], data_shape[1], \"data\" in dataset.keys(), \"target\" in dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['data']\n",
    "y = dataset['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SCALING \n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a MLP with the same settings as the sample workbook. (Everything default, 3 hidden layers with 30 neurons each). Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30, 30))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16   2   4   0   1   0   1]\n",
      " [  0  54   1   5   0   0   1]\n",
      " [  1   0  21   5   3   0   0]\n",
      " [  1   3   2 113   4   1   1]\n",
      " [  1   0   1   2  18   2   4]\n",
      " [  0   0   0   2   1  15   0]\n",
      " [  0   2   1   4   1   2  26]]\n",
      "\n",
      "R2 Score: 0.6311847574107351\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.74        24\n",
      "           1       0.89      0.89      0.89        61\n",
      "           2       0.70      0.70      0.70        30\n",
      "           3       0.86      0.90      0.88       125\n",
      "           4       0.64      0.64      0.64        28\n",
      "           5       0.75      0.83      0.79        18\n",
      "           6       0.79      0.72      0.75        36\n",
      "\n",
      "    accuracy                           0.82       322\n",
      "   macro avg       0.78      0.76      0.77       322\n",
      "weighted avg       0.82      0.82      0.82       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print()\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score:\",r2_score(y_test, predictions))\n",
    "print()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase your learning rate (alpha) to 0.1. Retrain and retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16   4   2   0   1   0   1]\n",
      " [  0  52   0   5   0   0   4]\n",
      " [  1   1  20   6   2   0   0]\n",
      " [  1   5   2 112   2   0   3]\n",
      " [  0   0   2   4  20   0   2]\n",
      " [  0   0   0   2   2  14   0]\n",
      " [  1   2   1   3   1   1  27]]\n",
      "\n",
      "R2 Score: 0.5284906928574369\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.74        24\n",
      "           1       0.81      0.85      0.83        61\n",
      "           2       0.74      0.67      0.70        30\n",
      "           3       0.85      0.90      0.87       125\n",
      "           4       0.71      0.71      0.71        28\n",
      "           5       0.93      0.78      0.85        18\n",
      "           6       0.73      0.75      0.74        36\n",
      "\n",
      "    accuracy                           0.81       322\n",
      "   macro avg       0.80      0.76      0.78       322\n",
      "weighted avg       0.81      0.81      0.81       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30),alpha=0.1)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print()\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score:\",r2_score(y_test, predictions))\n",
    "print()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change your learning rate back to default. Decrease your momentum to 0.1. Retrain and retest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15   5   2   1   1   0   0]\n",
      " [  0  52   0   5   0   0   4]\n",
      " [  1   2  19   5   2   0   1]\n",
      " [  1   3   2 114   3   0   2]\n",
      " [  0   0   2   1  18   2   5]\n",
      " [  0   0   0   3   5   9   1]\n",
      " [  2   2   1   3   2   1  25]]\n",
      "\n",
      "R2 Score: 0.49205086349981486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.70        24\n",
      "           1       0.81      0.85      0.83        61\n",
      "           2       0.73      0.63      0.68        30\n",
      "           3       0.86      0.91      0.89       125\n",
      "           4       0.58      0.64      0.61        28\n",
      "           5       0.75      0.50      0.60        18\n",
      "           6       0.66      0.69      0.68        36\n",
      "\n",
      "    accuracy                           0.78       322\n",
      "   macro avg       0.74      0.69      0.71       322\n",
      "weighted avg       0.78      0.78      0.78       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30),alpha=0.0001, momentum=0.1)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print()\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score:\",r2_score(y_test, predictions))\n",
    "print()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep momentum the same. Increase max_iter to 1000. Retrain and retest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15   5   3   0   1   0   0]\n",
      " [  0  50   1   5   0   1   4]\n",
      " [  1   0  22   5   2   0   0]\n",
      " [  0   2   3 115   4   0   1]\n",
      " [  0   0   2   4  17   2   3]\n",
      " [  0   1   0   2   2  12   1]\n",
      " [  0   2   2   3   2   0  27]]\n",
      "\n",
      "R2 Score: 0.5792856065074553\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.75        24\n",
      "           1       0.83      0.82      0.83        61\n",
      "           2       0.67      0.73      0.70        30\n",
      "           3       0.86      0.92      0.89       125\n",
      "           4       0.61      0.61      0.61        28\n",
      "           5       0.80      0.67      0.73        18\n",
      "           6       0.75      0.75      0.75        36\n",
      "\n",
      "    accuracy                           0.80       322\n",
      "   macro avg       0.78      0.73      0.75       322\n",
      "weighted avg       0.80      0.80      0.80       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30),alpha=0.0001, momentum=0.1,max_iter=1000)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print()\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score:\",r2_score(y_test, predictions))\n",
    "print()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try to build a model with the highest level of accuracy you can. You can change any of the parameters including max_iter, alpha, momentum, and hidden layers. Take your time testing different configurations until you find one you like.\n",
    "\n",
    "\n",
    "\n",
    "NOTE*: Since grid search is being used, best would be not to run this code, just run the last block of this code, cause it will take a lot of time and can cause an error is the system does not have required memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(500,500,500), (400,400,400),(300,300,300),(200,200,200)],\n",
    "    'momentum':[0.9,0.8,0.6,0.5],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'max_iter':[1000,2000,3000,4000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001],\n",
       "                         'hidden_layer_sizes': [(500, 500, 500),\n",
       "                                                (400, 400, 400),\n",
       "                                                (300, 300, 300),\n",
       "                                                (200, 200, 200)],\n",
       "                         'max_iter': [1000, 2000, 3000, 4000],\n",
       "                         'momentum': [0.9, 0.8, 0.6, 0.5]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "mlp = MLPClassifier()\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'alpha': 0.0001, 'hidden_layer_sizes': (500, 500, 500), 'max_iter': 1000, 'momentum': 0.5}\n"
     ]
    }
   ],
   "source": [
    "sorted(clf.cv_results_.keys())\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(500,500,500),alpha=0.0001, momentum=0.5,max_iter=1000)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14   5   2   1   1   0   1]\n",
      " [  0  55   0   3   0   0   3]\n",
      " [  1   2  20   5   2   0   0]\n",
      " [  0   3   3 116   0   0   3]\n",
      " [  0   0   2   3  17   0   6]\n",
      " [  0   0   0   3   1  12   2]\n",
      " [  0   2   1   4   5   0  24]]\n",
      "\n",
      "R2 Score: 0.5649305222150588\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.58      0.72        24\n",
      "           1       0.82      0.90      0.86        61\n",
      "           2       0.71      0.67      0.69        30\n",
      "           3       0.86      0.93      0.89       125\n",
      "           4       0.65      0.61      0.63        28\n",
      "           5       1.00      0.67      0.80        18\n",
      "           6       0.62      0.67      0.64        36\n",
      "\n",
      "    accuracy                           0.80       322\n",
      "   macro avg       0.80      0.72      0.75       322\n",
      "weighted avg       0.81      0.80      0.80       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print()\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score:\",r2_score(y_test, predictions))\n",
    "print()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
